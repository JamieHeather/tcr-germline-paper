# -*- coding: utf-8 -*-

from datetime import datetime
import os
import matplotlib.pyplot as plt
import math
import textwrap
import pandas as pd


def today(date_format=''):
    """
    :return: Today's date, in one of two formats, defaulting to ISO
    """
    date_today = datetime.today().date().isoformat()
    if date_format == 'ncbi':
        date_today = datetime.strptime(date_today, '%Y-%m-%d').strftime('%d-%b-%Y').upper()
    return date_today


def iso(date_str):
    """
    :param date_str: str detailing a date in ISO format
    :return: datetime formatted ISO date
    """
    return datetime.fromisoformat(date_str)


def readfq(fastx_file):
    """
    readfq(file):Heng Li's Python implementation of his readfq function
    https://github.com/lh3/readfq/blob/master/readfq.py
    :param fastx_file: opened file containing fastq or fasta reads
    :yield: read id, read sequence, and (where available) read quality scores
    """

    last = None  # this is a buffer keeping the last unprocessed line
    while True:
        if not last:  # the first record or a record following a fastq
            for l in fastx_file:  # search for the start of the next record
                if l[0] in '>@':  # fasta/q header line
                    last = l[:-1]  # save this line
                    break

        if not last:
            break

        name, seqs, last = last[1:], [], None  # This version takes the whole line (post '>')
        for l in fastx_file:  # read the sequence
            if l[0] in '@+>':
                last = l[:-1]
                break
            seqs.append(l[:-1])

        if not last or last[0] != '+':  # this is a fasta record
            yield name, ''.join(seqs), None  # yield a fasta record
            if not last:
                break

        else:  # this is a fastq record
            sequence, leng, seqs = ''.join(seqs), 0, []
            for l in fastx_file:  # read the quality
                seqs.append(l[:-1])
                leng += len(l) - 1
                if leng >= len(sequence):  # have read enough quality
                    last = None
                    yield name, sequence, ''.join(seqs)  # yield a fastq record
                    break

            if last:  # reach EOF before reading enough quality
                yield name, sequence, None  # yield a fasta record instead
                break


def list_to_df(input_list, headers, rename):
    """
    Convert a list to a (long) dataframe. Note that first entry becomes the index if chosen
    :param input_list: List of list entries (with each position in each list corresponding to a column)
    :param headers: List of column headers. First column should be unique, becoming the rownames, if rename = True
    :param rename: Option to rename row IDs by first colum
    :return: sorted pandas dataframe
    """
    df = pd.DataFrame(input_list)
    df = df.rename(index=str, columns=dict(zip(range(len(headers)), headers)))
    df = df.sort_values(by=[headers[0]])
    if rename is True:
        df = df.set_index(headers[0], drop=True)
    return df


def pc_rounding(val):
    if val > 10:
        round_to = 10
    elif val > 1:
        round_to = 1
    else:
        round_to = 0.1
    return math.ceil(val / round_to) * round_to


def halfway(x1, x2):
    return x1 + ((x2-x1)/2)


def fastafy(gene, seq_line):
    """
    :param gene: Gene symbol, extracted from the read id
    :param seq_line: Total protein primary sequence, extracted from input FASTA/generated by in silico splicing
    :return: An output-compatible FASTA entry ready for writing to file
    """
    return ">" + gene + "\n" + textwrap.fill(seq_line, 60) + "\n"


def get_novel_alleles(study_threshold, donor_threshold, file_to_add_to):
    """
    Note that this function is modified from stitchrdl, v0.3.0
    :param study_threshold: int of # of studies a given allele must be found in to be retained
    :param donor_threshold: int of # of donors a given allele must be found in to be retained, summed across all studies
    This function grabs novel alleles from the repo where I collate them, and reads them into the additional-genes file
    """

    summary_prefix = 'novel-TCR-alleles-'
    novel_file_name = ''
    matching_files = [x for x in os.listdir(novel_dir) if x.startswith(summary_prefix)]
    if len(matching_files) == 1:
        novel_file_name = matching_files[0]

    if not novel_file_name:
        raise IOError("Unable to locate a suitable summary novel TCR allele file name in the cloned GitHub repository.")

    # If found, read in and whittle down to those entries that meet select criteria
    tsv_path = os.path.join(novel_dir, novel_file_name)
    novel = pd.read_csv(tsv_path, sep='\t')

    # Disregard alleles found in fewer than the requested # of studies/donors,
    # & those already featured in IMGT (in some form)
    novel['Notes'] = novel['Notes'].fillna('').astype('str').tolist()
    novel = novel.loc[(novel['Number-Datasets-In'] >= study_threshold) &
                      (novel['Number-Donors-In'] > donor_threshold) &
                      (novel['IMGT-ID'].isna()) &
                      ~(novel['Notes'].str.contains('Shorter version of IMGT'))]

    # If a FASTA path isn't supplied, simply return the df
    if not file_to_add_to:
        return novel

    with open(file_to_add_to, 'a') as out_file:
        for row in novel.index:
            row_bits = novel.loc[row]
            if pd.isna(row_bits['Notes']):
                notes = ''
            else:
                notes = str(row_bits['Notes'])
            func = '?'

            if 'Stop codon' in notes:
                func = 'P'

            # Determine whether the allele has a valid name
            allele_id = ''
            if row_bits['Standard-ID'].startswith('TR'):
                allele_id = row_bits['Standard-ID']
            else:
                # If not, borrow one of the names from the paper(s) where it was discovered
                studies = [x for x in novel if '-Name' in x]
                for study in studies:
                    if not pd.isna(row_bits[study]):
                        allele_id = row_bits[study] + '-' + study.replace('-Name', '')
                        if allele_id[:2] != 'TR' or '*' not in allele_id:
                            allele_id = row_bits['Gene'] + '*' + allele_id

            if not allele_id:
                raise IOError("Unable to determine a possible allele ID for sequence with data:\n" + str(row_bits))

            else:
                out_file.write(fastafy(allele_id, row_bits['Ungapped-Sequence']))


def aa2nt(aa_number):
    """
    Convert IMGT amino acid number (1-indexed) to the codon's first nucleotide index (0-indexed)
    :param aa_number: int of amino acid index in IMGT numbering
    :return: int of nucleotide index in IMGT numbering
    """
    return 3 * aa_number - 3


def nt2aa(nt_number):
    """
    Convert nucleotide index (0-indexed) to IMGT amino acid number (1-indexed)
    :param nt_number: int of nucleotide index in IMGT numbering
    :return: int of amino acid index in IMGT numbering
    """
    return round((nt_number - 1) / 3) + 1


def aa2region(aa_number):
    """
    Given an IMGT amino acid number (1-indexed) return a str of which V gene section it falls in
    :param aa_number: int of amino acid index in IMGT numbering
    :return: str detailing the framework or complementarity determining region of said amino acid
    """

    if aa_number > 125:
        raise IOError("Unexpectedly high amino acid number!")
    elif aa_number >= 104:
        return 'CDR3'
    elif aa_number >= 66:
        return 'FR3'
    elif aa_number >= 56:
        return 'CDR2'
    elif aa_number >= 39:
        return 'FR2'
    elif aa_number >= 27:
        return 'CDR1'
    elif aa_number >= 1:
        return 'FR1'
    else:
        raise IOError("Inappropriate amino acid number!")


codons = {'AAA': 'K', 'AAC': 'N', 'AAG': 'K', 'AAT': 'N',
          'ACA': 'T', 'ACC': 'T', 'ACG': 'T', 'ACT': 'T',
          'AGA': 'R', 'AGC': 'S', 'AGG': 'R', 'AGT': 'S',
          'ATA': 'I', 'ATC': 'I', 'ATG': 'M', 'ATT': 'I',
          'CAA': 'Q', 'CAC': 'H', 'CAG': 'Q', 'CAT': 'H',
          'CCA': 'P', 'CCC': 'P', 'CCG': 'P', 'CCT': 'P',
          'CGA': 'R', 'CGC': 'R', 'CGG': 'R', 'CGT': 'R',
          'CTA': 'L', 'CTC': 'L', 'CTG': 'L', 'CTT': 'L',
          'GAA': 'E', 'GAC': 'D', 'GAG': 'E', 'GAT': 'D',
          'GCA': 'A', 'GCC': 'A', 'GCG': 'A', 'GCT': 'A',
          'GGA': 'G', 'GGC': 'G', 'GGG': 'G', 'GGT': 'G',
          'GTA': 'V', 'GTC': 'V', 'GTG': 'V', 'GTT': 'V',
          'TAA': '*', 'TAC': 'Y', 'TAG': '*', 'TAT': 'Y',
          'TCA': 'S', 'TCC': 'S', 'TCG': 'S', 'TCT': 'S',
          'TGA': '*', 'TGC': 'C', 'TGG': 'W', 'TGT': 'C',
          'TTA': 'L', 'TTC': 'F', 'TTG': 'L', 'TTT': 'F'}


def translate(nt_seq):
    """
    :param nt_seq: Nucleotide sequence to be translated
    :return: corresponding amino acid sequence
    """
    aa_seq = ''
    nt_seq = nt_seq.upper()
    for i in range(0, len(nt_seq), 3):
        codon = nt_seq[i:i+3]
        if len(codon) == 3:
            try:
                aa_seq += codons[codon]
            except Exception:
                raise IOError("Cannot translate codon: " + codon)
    return aa_seq


def nt2region(nt_number):
    # Given a V gene nucleotide number (0-indexed) return a str of which V gene section it falls in
    return aa2region(nt2aa(nt_number))


plot_dir = os.path.join('..', 'plots')
release_dir = os.path.join('..', 'genedb-releases', 'releases')
ref_dir = os.path.join('..', 'reference-data')
novel_dir = os.path.join('..', 'novel-tcr-alleles')
mikelov_dir = os.path.join('..', 'mikelov-data')


def get_plot_dir(name):
    """
    :param name: str detailing name to append to today's date for generating specific plot directories
    :return: path of said plot directory (after creating it)
    """
    new_path = os.path.join(plot_dir, today() + '_' + name)

    if not os.path.exists(new_path):
        os.makedirs(new_path)

    return new_path


def get_most_recent_genedb(search_str='fasta-nt-WithoutGaps-F+ORF+allP'):
    """
    Find the most recent IMGT/GENE-DB release directory/data, for up-to-date analysis comparison
    :param search_str: str detailing name of relevant file to find in th
    :return: dd (str, most recent data directory name), dd_path (str, path to directory), fl_path (str, full path,
     year (str, YYYY), date (str, YYYY-MM-DD), source (str, name of DB), release (str)
    """
    data_dirs = [x for x in os.listdir(release_dir)
                 if os.path.isdir(os.path.join(release_dir, x)) and x.startswith('20')]
    data_dirs.sort()

    dd = data_dirs[-1]

    # Check file exists
    search = [x for x in os.listdir(os.path.join(release_dir, dd)) if search_str in x]
    if len(search) == 1:
        fl = search[0]
    else:
        raise IOError('Most recent directory lacks the proper file! Ending script.')

    fl_path = os.path.join(release_dir, dd, fl)

    year = dd[:4]
    date, source, release = dd.replace('/', '').split('_')
    dd_path = os.path.join(release_dir, dd)
    return dd, dd_path, fl_path, year, date, source, release
